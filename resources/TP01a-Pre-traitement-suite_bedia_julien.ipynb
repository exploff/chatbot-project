{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "96764245-c247-42a8-a6a9-a68b1ce08d1f",
   "metadata": {},
   "source": [
    "---\n",
    "<center><h1>Suite Pré-traitement BEDIA JULIEN</h1></center>\n",
    "\n",
    "---\n",
    "## Sujet\n",
    "\n",
    "Dans la continuité du tp précédent, nous allons couvrir les méthodes de prétraitement suivantes:\n",
    "- Mots vides\n",
    "- Racinisation/lématisation\n",
    "- Étiquetage morpho-syntaxique\n",
    "- Reconnaissance d'entités nommées\n",
    "\n",
    "Avant tout, un défi est proposé sur les méthodes vues dans le tp précédent.\n",
    "\n",
    "## Compétences visées\n",
    "\n",
    "- Découvrir les différentes formes que peuvent revétir un chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faea818-18e7-4f00-998e-5cc777578a33",
   "metadata": {},
   "source": [
    "### Défi\n",
    "\n",
    "\n",
    "Dans la section `Lecture de fichiers` du notebook précedent `pre_traitement` et précisément la sous-section `défi`, vous avez chargé des commentaires d'Amazon. Pour chaque commentaire :\n",
    "- Enlever tous les espaces blancs\n",
    "- Mettre tous les caractères en minuscules\n",
    "- Remplacer les URL et les chiffres\n",
    "\n",
    "Puis trouvez les 60 mots les plus courants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c17fad81-eb86-46c5-9587-4be37855e072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les 60 mots les plus courants sont :  [('the', 1870897), ('i', 1681591), ('and', 1289746), ('a', 1235413), ('it', 1072734), ('to', 1015461), ('of', 802044), ('is', 734333), ('this', 670977), ('br', 646925), ('for', 552420), ('in', 547858), ('DIGIT', 519783), ('my', 462143), ('that', 454229), ('but', 376344), ('you', 369377), ('with', 353137), ('have', 345430), ('not', 335004), ('are', 318982), ('was', 315635), ('they', 314438), ('t', 301822), ('s', 301551), ('as', 279663), ('on', 272477), ('like', 256128), ('so', 256057), ('these', 233116), ('them', 211553), ('good', 200223), ('be', 189189), ('or', 181751), ('at', 180137), ('one', 176694), ('can', 174255), ('just', 172825), ('taste', 172652), ('if', 169938), ('very', 167356), ('great', 166583), ('coffee', 166205), ('all', 159729), ('product', 151249), ('flavor', 147836), ('from', 145952), ('we', 144455), ('tea', 138070), ('when', 136243), ('more', 135891), ('has', 131338), ('me', 130561), ('food', 128418), ('had', 127310), ('love', 127269), ('will', 127161), ('would', 124295), ('out', 116052), ('than', 114511)]\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Expression régulière pour identifier les URLs\n",
    "url_regex = r'http\\S+'\n",
    "\n",
    "# Expression régulière pour identifier les chiffres\n",
    "digit_regex = r'\\d+'\n",
    "\n",
    "# Fonction pour faire la subsititution\n",
    "def replace_pattern_sub(pattern, repl, text):\n",
    "    return re.sub(pattern, repl, text)\n",
    "\n",
    "def clean_text(text):\n",
    "    # Supprimer les espaces blancs\n",
    "    text = text.strip()\n",
    "\n",
    "    text = text.lower()\n",
    "    \n",
    "    # replace url, chiffre\n",
    "    text = replace_pattern_sub(url_regex, 'URL', text)\n",
    "    text = replace_pattern_sub(digit_regex, 'DIGIT', text)\n",
    "\n",
    "\n",
    "    return text\n",
    "\n",
    "dossier = \"./amazon\"\n",
    "#n_files_to_read = 5\n",
    "header = []  # initial value for header\n",
    "\n",
    "contents = []\n",
    "for i, file_name in enumerate(os.listdir(dossier)):\n",
    "    file_path = os.path.join(dossier, file_name)\n",
    "    if not header:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')\n",
    "        header = df.columns.tolist()\n",
    "    else:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8', header=None, names=header)\n",
    "    contents.append(df['Text'])\n",
    "contents = pd.concat(contents).tolist()\n",
    "\n",
    "# nettoyage de chaque valeurs dans la liste contents :\n",
    "contents = [clean_text(text) for text in contents]\n",
    "\n",
    "# concaténation de tous les textes\n",
    "all_comments = ''.join(contents)\n",
    "\n",
    "# tokenisation\n",
    "PATTERN = r'\\w+'\n",
    "regexpTokenizer = nltk.tokenize.RegexpTokenizer(PATTERN)\n",
    "tokens = regexpTokenizer.tokenize(all_comments)\n",
    "\n",
    "# Compter le nombre d'occurrences de chaque mot\n",
    "word_counts = Counter(tokens)\n",
    "\n",
    "# Trouver les 5 mots les plus courants\n",
    "top_words = word_counts.most_common(60)\n",
    "print(\"Les 60 mots les plus courants sont : \", top_words)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ef54163",
   "metadata": {},
   "source": [
    "Résultats :\n",
    "\n",
    "Les 60 mots les plus courants sont :  [('the', 1870897), ('i', 1681591), ('and', 1289746), ('a', 1235413), ('it', 1072734), ('to', 1015461), ('of', 802044), ('is', 734333), ('this', 670977), ('br', 646925), ('for', 552420), ('in', 547858), ('DIGIT', 519783), ('my', 462143), ('that', 454229), ('but', 376344), ('you', 369377), ('with', 353137), ('have', 345430), ('not', 335004), ('are', 318982), ('was', 315635), ('they', 314438), ('t', 301822), ('s', 301551), ('as', 279663), ('on', 272477), ('like', 256128), ('so', 256057), ('these', 233116), ('them', 211553), ('good', 200223), ('be', 189189), ('or', 181751), ('at', 180137), ('one', 176694), ('can', 174255), ('just', 172825), ('taste', 172652), ('if', 169938), ('very', 167356), ('great', 166583), ('coffee', 166205), ('all', 159729), ('product', 151249), ('flavor', 147836), ('from', 145952), ('we', 144455), ('tea', 138070), ('when', 136243), ('more', 135891), ('has', 131338), ('me', 130561), ('food', 128418), ('had', 127310), ('love', 127269), ('will', 127161), ('would', 124295), ('out', 116052), ('than', 114511)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad29aef3-06f0-4770-a708-7e472275874a",
   "metadata": {},
   "source": [
    "## Suppression des mots vides\n",
    "\n",
    "Vous avez peut-être remarqué que les mots les plus courants ci-dessus ne sont pas très intéressants. Il s'agit de mots comme \"am\", \"i\", \"the\" et \"a\" : des mots vides. Ils nous sont rarement utiles dans l'analyse de texte, et il est donc très courant de les supprimer complètement.\n",
    "\n",
    "- Quels sont les autres mots vides qui existent dans la langue anglaise?\n",
    "\n",
    "Pour répondre à cette question, afficher la liste des mots vides du module `nltk.corpus` (voir documentation officielle de `nltk`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dc6f91d-8053-43df-b7c1-48bc88c2f844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Julien\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab29c1a-a619-43ea-a540-734e348e7ee7",
   "metadata": {},
   "source": [
    "### Défi\n",
    "\n",
    "Utilisez la liste de ces mots vides anglais pour nettoyer de mots vides les commentaires Amazon chargés au-dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05ced9f6-ddef-4105-b89f-9933335ee583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('br', 646925), ('DIGIT', 519783), ('like', 256128), ('good', 200223), ('one', 176694), ('taste', 172652), ('great', 166583), ('coffee', 166205), ('product', 151249), ('flavor', 147836), ('tea', 138070), ('food', 128418), ('love', 127269), ('would', 124295), ('get', 108740), ('really', 101012), ('much', 93093), ('amazon', 89898), ('also', 86860), ('time', 84609), ('use', 83880), ('little', 83492), ('buy', 76808), ('best', 76665), ('tried', 76455), ('price', 75786), ('even', 74959), ('find', 73513), ('well', 73235), ('make', 71997), ('better', 70653), ('dog', 69817), ('try', 69155), ('eat', 67717), ('cup', 62856), ('first', 61937), ('water', 61585), ('chocolate', 61079), ('bag', 58195), ('sugar', 57324), ('used', 54403), ('found', 54116), ('sweet', 52647), ('made', 51315), ('drink', 51144), ('box', 50786), ('free', 50658), ('bought', 50241), ('way', 49547), ('two', 49455), ('think', 49162), ('day', 48792), ('since', 46511), ('go', 46322), ('store', 45878), ('tastes', 45579), ('still', 45441), ('could', 44975), ('order', 44595), ('know', 43616)]\n"
     ]
    }
   ],
   "source": [
    "filtered_words = [word for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "# Compter le nombre d'occurrences de chaque mot restant\n",
    "word_counts = Counter(filtered_words)\n",
    "\n",
    "# Trouver les 60 mots les plus courants\n",
    "top_words = word_counts.most_common(60)\n",
    "\n",
    "print(top_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c9a8925",
   "metadata": {},
   "source": [
    "Les 60 mots les plus courants :\n",
    "\n",
    "[('br', 646925), ('DIGIT', 519783), ('like', 256128), ('good', 200223), ('one', 176694), ('taste', 172652), ('great', 166583), ('coffee', 166205), ('product', 151249), ('flavor', 147836), ('tea', 138070), ('food', 128418), ('love', 127269), ('would', 124295), ('get', 108740), ('really', 101012), ('much', 93093), ('amazon', 89898), ('also', 86860), ('time', 84609), ('use', 83880), ('little', 83492), ('buy', 76808), ('best', 76665), ('tried', 76455), ('price', 75786), ('even', 74959), ('find', 73513), ('well', 73235), ('make', 71997), ('better', 70653), ('dog', 69817), ('try', 69155), ('eat', 67717), ('cup', 62856), ('first', 61937), ('water', 61585), ('chocolate', 61079), ('bag', 58195), ('sugar', 57324), ('used', 54403), ('found', 54116), ('sweet', 52647), ('made', 51315), ('drink', 51144), ('box', 50786), ('free', 50658), ('bought', 50241), ('way', 49547), ('two', 49455), ('think', 49162), ('day', 48792), ('since', 46511), ('go', 46322), ('store', 45878), ('tastes', 45579), ('still', 45441), ('could', 44975), ('order', 44595), ('know', 43616)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a6d6f7-8b38-4406-9a4e-8f9828077abc",
   "metadata": {},
   "source": [
    "##  Etiquettage morpho-syntaxique\n",
    "\n",
    "L'étiquettage morpho-syntaxique consiste à assigner à chaque token les informations grammaticales associées (par exemple un nom, un verbe, un adjectif, etc.). NLTK propose plusieurs étiquetteurs. Nous nous focalisons sur l'étiquetteur `pos_tag`. Lors de l'étiquetage, il est conseillé de ne pas supprimer les mots vides au préalable. \n",
    "\n",
    "Choisissez les 10 premiers commentaires Amazon que vous avez déjà chargés puis appliquez l'opération de tokénisation. Ensuite utiliser l'étiquetteur `pos_tag` sur chacun de ces commentaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd909a4d-8c1e-4d56-8187-a3d259ff77fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Julien\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('i', 'NNS'),\n",
       " ('have', 'VBP'),\n",
       " ('bought', 'VBN'),\n",
       " ('several', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('vitality', 'NN'),\n",
       " ('canned', 'VBD'),\n",
       " ('dog', 'JJ'),\n",
       " ('food', 'NN'),\n",
       " ('products', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('have', 'VBP'),\n",
       " ('found', 'VBN'),\n",
       " ('them', 'PRP'),\n",
       " ('all', 'DT'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('of', 'IN'),\n",
       " ('good', 'JJ'),\n",
       " ('quality', 'NN'),\n",
       " ('the', 'DT'),\n",
       " ('product', 'NN'),\n",
       " ('looks', 'VBZ'),\n",
       " ('more', 'RBR'),\n",
       " ('like', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('stew', 'NN'),\n",
       " ('than', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('processed', 'JJ'),\n",
       " ('meat', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " ('smells', 'VBZ'),\n",
       " ('better', 'RBR'),\n",
       " ('my', 'PRP$'),\n",
       " ('labrador', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('finicky', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('she', 'PRP'),\n",
       " ('appreciates', 'VBZ'),\n",
       " ('this', 'DT'),\n",
       " ('product', 'NN'),\n",
       " ('better', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('most', 'JJS'),\n",
       " ('product', 'NN'),\n",
       " ('arrived', 'VBD'),\n",
       " ('labeled', 'VBN'),\n",
       " ('as', 'IN'),\n",
       " ('jumbo', 'NN'),\n",
       " ('salted', 'VBD'),\n",
       " ('peanuts', 'NNS'),\n",
       " ('the', 'DT'),\n",
       " ('peanuts', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('actually', 'RB'),\n",
       " ('small', 'JJ'),\n",
       " ('sized', 'VBN'),\n",
       " ('unsalted', 'JJ'),\n",
       " ('not', 'RB'),\n",
       " ('sure', 'JJ'),\n",
       " ('if', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('was', 'VBD'),\n",
       " ('an', 'DT'),\n",
       " ('error', 'NN'),\n",
       " ('or', 'CC'),\n",
       " ('if', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('vendor', 'NN'),\n",
       " ('intended', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('represent', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('product', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('jumbo', 'JJ'),\n",
       " ('this', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('confection', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('has', 'VBZ'),\n",
       " ('been', 'VBN'),\n",
       " ('around', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('few', 'JJ'),\n",
       " ('centuries', 'NNS'),\n",
       " ('it', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('light', 'JJ'),\n",
       " ('pillowy', 'NN'),\n",
       " ('citrus', 'NN'),\n",
       " ('gelatin', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('nuts', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('case', 'NN'),\n",
       " ('filberts', 'VBZ'),\n",
       " ('and', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('cut', 'VBN'),\n",
       " ('into', 'IN'),\n",
       " ('tiny', 'JJ'),\n",
       " ('squares', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('then', 'RB'),\n",
       " ('liberally', 'RB'),\n",
       " ('coated', 'VBN'),\n",
       " ('with', 'IN'),\n",
       " ('powdered', 'JJ'),\n",
       " ('sugar', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('tiny', 'JJ'),\n",
       " ('mouthful', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('heaven', 'NN'),\n",
       " ('not', 'RB'),\n",
       " ('too', 'RB'),\n",
       " ('chewy', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('very', 'RB'),\n",
       " ('flavorful', 'JJ'),\n",
       " ('i', 'NN'),\n",
       " ('highly', 'RB'),\n",
       " ('recommend', 'VB'),\n",
       " ('this', 'DT'),\n",
       " ('yummy', 'NN'),\n",
       " ('treat', 'NN'),\n",
       " ('if', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('familiar', 'JJ'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('story', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('c', 'NN'),\n",
       " ('s', 'NN'),\n",
       " ('lewis', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('lion', 'NN'),\n",
       " ('the', 'DT'),\n",
       " ('witch', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('wardrobe', 'NN'),\n",
       " ('this', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('treat', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('seduces', 'VBZ'),\n",
       " ('edmund', 'RB'),\n",
       " ('into', 'IN'),\n",
       " ('selling', 'VBG'),\n",
       " ('out', 'RP'),\n",
       " ('his', 'PRP$'),\n",
       " ('brother', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('sisters', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('witch', 'NN'),\n",
       " ('if', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('looking', 'VBG'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('secret', 'JJ'),\n",
       " ('ingredient', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('robitussin', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('believe', 'VBP'),\n",
       " ('i', 'NN'),\n",
       " ('have', 'VBP'),\n",
       " ('found', 'VBN'),\n",
       " ('it', 'PRP'),\n",
       " ('i', 'JJ'),\n",
       " ('got', 'VBD'),\n",
       " ('this', 'DT'),\n",
       " ('in', 'IN'),\n",
       " ('addition', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('root', 'NN'),\n",
       " ('beer', 'NN'),\n",
       " ('extract', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('ordered', 'VBD'),\n",
       " ('which', 'WDT'),\n",
       " ('was', 'VBD'),\n",
       " ('good', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('made', 'VBD'),\n",
       " ('some', 'DT'),\n",
       " ('cherry', 'JJ'),\n",
       " ('soda', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('flavor', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('very', 'RB'),\n",
       " ('medicinal', 'JJ'),\n",
       " ('great', 'JJ'),\n",
       " ('taffy', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('great', 'JJ'),\n",
       " ('price', 'NN'),\n",
       " ('there', 'EX'),\n",
       " ('was', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('wide', 'JJ'),\n",
       " ('assortment', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('yummy', 'NN'),\n",
       " ('taffy', 'NN'),\n",
       " ('delivery', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('very', 'RB'),\n",
       " ('quick', 'JJ'),\n",
       " ('if', 'IN'),\n",
       " ('your', 'PRP$'),\n",
       " ('a', 'DT'),\n",
       " ('taffy', 'NN'),\n",
       " ('lover', 'NN'),\n",
       " ('this', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('deal', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('got', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('wild', 'JJ'),\n",
       " ('hair', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('taffy', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('ordered', 'VBD'),\n",
       " ('this', 'DT'),\n",
       " ('five', 'CD'),\n",
       " ('pound', 'NN'),\n",
       " ('bag', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('taffy', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('all', 'DT'),\n",
       " ('very', 'RB'),\n",
       " ('enjoyable', 'JJ'),\n",
       " ('with', 'IN'),\n",
       " ('many', 'JJ'),\n",
       " ('flavors', 'NNS'),\n",
       " ('watermelon', 'VBP'),\n",
       " ('root', 'NN'),\n",
       " ('beer', 'NN'),\n",
       " ('melon', 'NN'),\n",
       " ('peppermint', 'NN'),\n",
       " ('grape', 'NN'),\n",
       " ('etc', 'VB'),\n",
       " ('my', 'PRP$'),\n",
       " ('only', 'JJ'),\n",
       " ('complaint', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('there', 'EX'),\n",
       " ('was', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('bit', 'NN'),\n",
       " ('too', 'RB'),\n",
       " ('much', 'JJ'),\n",
       " ('red', 'JJ'),\n",
       " ('black', 'JJ'),\n",
       " ('licorice', 'NN'),\n",
       " ('flavored', 'VBD'),\n",
       " ('pieces', 'NNS'),\n",
       " ('just', 'RB'),\n",
       " ('not', 'RB'),\n",
       " ('my', 'PRP$'),\n",
       " ('particular', 'JJ'),\n",
       " ('favorites', 'NNS'),\n",
       " ('between', 'IN'),\n",
       " ('me', 'PRP'),\n",
       " ('my', 'PRP$'),\n",
       " ('kids', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('my', 'PRP$'),\n",
       " ('husband', 'NN'),\n",
       " ('this', 'DT'),\n",
       " ('lasted', 'VBN'),\n",
       " ('only', 'RB'),\n",
       " ('two', 'CD'),\n",
       " ('weeks', 'NNS'),\n",
       " ('i', 'RB'),\n",
       " ('would', 'MD'),\n",
       " ('recommend', 'VB'),\n",
       " ('this', 'DT'),\n",
       " ('brand', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('taffy', 'NN'),\n",
       " ('it', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('delightful', 'JJ'),\n",
       " ('treat', 'NN'),\n",
       " ('this', 'DT'),\n",
       " ('saltwater', 'NN'),\n",
       " ('taffy', 'NN'),\n",
       " ('had', 'VBD'),\n",
       " ('great', 'JJ'),\n",
       " ('flavors', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('was', 'VBD'),\n",
       " ('very', 'RB'),\n",
       " ('soft', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('chewy', 'JJ'),\n",
       " ('each', 'DT'),\n",
       " ('candy', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('individually', 'RB'),\n",
       " ('wrapped', 'VBN'),\n",
       " ('well', 'RB'),\n",
       " ('none', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('candies', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('stuck', 'VBN'),\n",
       " ('together', 'RB'),\n",
       " ('which', 'WDT'),\n",
       " ('did', 'VBD'),\n",
       " ('happen', 'VB'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('expensive', 'JJ'),\n",
       " ('version', 'NN'),\n",
       " ('fralinger', 'NN'),\n",
       " ('s', 'NN'),\n",
       " ('would', 'MD'),\n",
       " ('highly', 'RB'),\n",
       " ('recommend', 'VB'),\n",
       " ('this', 'DT'),\n",
       " ('candy', 'NN'),\n",
       " ('i', 'VBZ'),\n",
       " ('served', 'VBD'),\n",
       " ('it', 'PRP'),\n",
       " ('at', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('beach', 'NN'),\n",
       " ('themed', 'VBN'),\n",
       " ('party', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('everyone', 'NN'),\n",
       " ('loved', 'VBD'),\n",
       " ('it', 'PRP'),\n",
       " ('this', 'DT'),\n",
       " ('taffy', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('so', 'RB'),\n",
       " ('good', 'JJ'),\n",
       " ('it', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('very', 'RB'),\n",
       " ('soft', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('chewy', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('flavors', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('amazing', 'VBG'),\n",
       " ('i', 'NN'),\n",
       " ('would', 'MD'),\n",
       " ('definitely', 'RB'),\n",
       " ('recommend', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('buying', 'VBG'),\n",
       " ('it', 'PRP'),\n",
       " ('very', 'RB'),\n",
       " ('satisfying', 'VBG'),\n",
       " ('right', 'RB'),\n",
       " ('now', 'RB'),\n",
       " ('i', 'JJ'),\n",
       " ('m', 'VBP'),\n",
       " ('mostly', 'RB'),\n",
       " ('just', 'RB'),\n",
       " ('sprouting', 'VBG'),\n",
       " ('this', 'DT'),\n",
       " ('so', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('cats', 'NNS'),\n",
       " ('can', 'MD'),\n",
       " ('eat', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('grass', 'NN'),\n",
       " ('they', 'PRP'),\n",
       " ('love', 'VBP'),\n",
       " ('it', 'PRP'),\n",
       " ('i', 'JJ'),\n",
       " ('rotate', 'VBP'),\n",
       " ('it', 'PRP'),\n",
       " ('around', 'IN'),\n",
       " ('with', 'IN'),\n",
       " ('wheatgrass', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('rye', 'NN'),\n",
       " ('toothis', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('very', 'RB'),\n",
       " ('healthy', 'JJ'),\n",
       " ('dog', 'NN'),\n",
       " ('food', 'NN'),\n",
       " ('good', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('digestion', 'NN'),\n",
       " ('also', 'RB'),\n",
       " ('good', 'JJ'),\n",
       " ('for', 'IN'),\n",
       " ('small', 'JJ'),\n",
       " ('puppies', 'NNS'),\n",
       " ('my', 'PRP$'),\n",
       " ('dog', 'NN'),\n",
       " ('eats', 'VBZ'),\n",
       " ('her', 'PRP$'),\n",
       " ('required', 'JJ'),\n",
       " ('amount', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('every', 'DT'),\n",
       " ('feeding', 'NN')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import pos_tag\n",
    "\n",
    "n_10_comments = (contents[:10])\n",
    "\n",
    "# nettoyage de chaque valeurs dans la liste contents :\n",
    "n_10_comments_clean = [clean_text(text) for text in n_10_comments]\n",
    "\n",
    "# concaténation de tous les textes\n",
    "n_10_comments = ''.join(n_10_comments_clean)\n",
    "\n",
    "# tokenisation\n",
    "PATTERN = r'\\w+'\n",
    "regexpTokenizer = nltk.tokenize.RegexpTokenizer(PATTERN)\n",
    "tokens = regexpTokenizer.tokenize(n_10_comments)\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fc57de-56b9-42eb-ae47-b93234b1031e",
   "metadata": {},
   "source": [
    "### Défi \n",
    "\n",
    "Charger le contenu du fichier 'sowing-and-reaping.txt'. Prétraitez-le en suivant les étapes suivantes :\n",
    "    \n",
    "- Supprimez les espaces blancs\n",
    "- Remplacez tous les chiffres par '0'\n",
    "- Convertissez le résultat en tokens\n",
    "- Marquez chaque token avec une étiquette morpho-synthaxique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88c066ba-dab7-4ea2-9677-e8c38f1d3fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'DT'),\n",
       " ('project', 'NN'),\n",
       " ('gutenberg', 'NN'),\n",
       " ('ebook', 'NN'),\n",
       " ('sowing', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('reaping', 'NN'),\n",
       " ('by', 'IN'),\n",
       " ('frances', 'NNS'),\n",
       " ('ellen', 'VBN'),\n",
       " ('watkins', 'NNS'),\n",
       " ('harper', 'RBR'),\n",
       " ('edited', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('frances', 'NNS'),\n",
       " ('smith', 'RB'),\n",
       " ('foster', 'RBR'),\n",
       " ('this', 'DT'),\n",
       " ('ebook', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('use', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('anyone', 'NN'),\n",
       " ('anywhere', 'RB'),\n",
       " ('at', 'IN'),\n",
       " ('no', 'DT'),\n",
       " ('cost', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('with', 'IN'),\n",
       " ('almost', 'RB'),\n",
       " ('no', 'DT'),\n",
       " ('restrictions', 'NNS'),\n",
       " ('whatsoever', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('may', 'MD'),\n",
       " ('copy', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('give', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('away', 'RB'),\n",
       " ('or', 'CC'),\n",
       " ('re', 'VB'),\n",
       " ('use', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('under', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('terms', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('project', 'NN'),\n",
       " ('gutenberg', 'NN'),\n",
       " ('license', 'NN'),\n",
       " ('included', 'VBD'),\n",
       " ('with', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('ebook', 'NN'),\n",
       " ('or', 'CC'),\n",
       " ('online', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('www', 'JJ'),\n",
       " ('gutenberg', 'JJ'),\n",
       " ('net', 'JJ'),\n",
       " ('title', 'NN'),\n",
       " ('sowing', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('reaping', 'VBG'),\n",
       " ('author', 'NN'),\n",
       " ('frances', 'NNS'),\n",
       " ('ellen', 'VBP'),\n",
       " ('watkins', 'VBZ'),\n",
       " ('harper', 'JJ'),\n",
       " ('release', 'NN'),\n",
       " ('date', 'NN'),\n",
       " ('february', 'JJ'),\n",
       " ('0', 'CD'),\n",
       " ('0', 'CD'),\n",
       " ('ebook', 'NN'),\n",
       " ('0', 'CD'),\n",
       " ('language', 'NN'),\n",
       " ('english', 'JJ'),\n",
       " ('character', 'NN'),\n",
       " ('set', 'VBN'),\n",
       " ('encoding', 'VBG'),\n",
       " ('us', 'PRP'),\n",
       " ('ascii', 'JJ'),\n",
       " ('start', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('project', 'NN'),\n",
       " ('gutenberg', 'NN'),\n",
       " ('ebook', 'NN'),\n",
       " ('sowing', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('reaping', 'VBG'),\n",
       " ('e', 'JJ'),\n",
       " ('text', 'NN'),\n",
       " ('prepared', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('juliet', 'JJ'),\n",
       " ('sutherland', 'NN'),\n",
       " ('andrea', 'NN'),\n",
       " ('ball', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('project', 'NN'),\n",
       " ('gutenberg', 'VBZ'),\n",
       " ('online', 'RP'),\n",
       " ('distributed', 'VBN'),\n",
       " ('proofreading', 'VBG'),\n",
       " ('team', 'NN'),\n",
       " ('transcriber', 'NN'),\n",
       " ('s', 'JJ'),\n",
       " ('note', 'NN'),\n",
       " ('this', 'DT'),\n",
       " ('document', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('text', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('sowing', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('reaping', 'VBG'),\n",
       " ('any', 'DT'),\n",
       " ('bracketed', 'JJ'),\n",
       " ('notations', 'NNS'),\n",
       " ('such', 'JJ'),\n",
       " ('as', 'IN'),\n",
       " ('text', 'NN'),\n",
       " ('missing', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('those', 'DT'),\n",
       " ('inserting', 'VBG'),\n",
       " ('letters', 'NNS'),\n",
       " ('or', 'CC'),\n",
       " ('other', 'JJ'),\n",
       " ('comments', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('from', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('original', 'JJ'),\n",
       " ('text', 'NN'),\n",
       " ('sowing', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('reaping', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('temperance', 'NN'),\n",
       " ('story', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('rediscovered', 'VBN'),\n",
       " ('novel', 'NN'),\n",
       " ('by', 'IN'),\n",
       " ('frances', 'NNS'),\n",
       " ('e', 'RB'),\n",
       " ('w', 'VBP'),\n",
       " ('harper', 'NN'),\n",
       " ('edited', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('frances', 'NNS'),\n",
       " ('smith', 'JJ'),\n",
       " ('foster', 'JJ'),\n",
       " ('chapter', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('i', 'VBP'),\n",
       " ('hear', 'VBP'),\n",
       " ('that', 'IN'),\n",
       " ('john', 'NN'),\n",
       " ('andrews', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('given', 'VBN'),\n",
       " ('up', 'RP'),\n",
       " ('his', 'PRP$'),\n",
       " ('saloon', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('a', 'DT'),\n",
       " ('foolish', 'JJ'),\n",
       " ('thing', 'NN'),\n",
       " ('it', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('he', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('doing', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('splendid', 'NN'),\n",
       " ('business', 'NN'),\n",
       " ('what', 'WP'),\n",
       " ('could', 'MD'),\n",
       " ('have', 'VB'),\n",
       " ('induced', 'VBN'),\n",
       " ('him', 'PRP'),\n",
       " ('they', 'PRP'),\n",
       " ('say', 'VBP'),\n",
       " ('that', 'IN'),\n",
       " ('his', 'PRP$'),\n",
       " ('wife', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('bitterly', 'RB'),\n",
       " ('opposed', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('business', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('don', 'VBP'),\n",
       " ('t', 'NN'),\n",
       " ('know', 'VBP'),\n",
       " ('but', 'CC'),\n",
       " ('i', 'VBP'),\n",
       " ('think', 'VBP'),\n",
       " ('it', 'PRP'),\n",
       " ('quite', 'RB'),\n",
       " ('likely', 'JJ'),\n",
       " ('she', 'PRP'),\n",
       " ('has', 'VBZ'),\n",
       " ('never', 'RB'),\n",
       " ('seemed', 'VBN'),\n",
       " ('happy', 'JJ'),\n",
       " ('since', 'IN'),\n",
       " ('john', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('kept', 'VBN'),\n",
       " ('saloon', 'RB'),\n",
       " ('well', 'RB'),\n",
       " ('i', 'RB'),\n",
       " ('would', 'MD'),\n",
       " ('never', 'RB'),\n",
       " ('let', 'VB'),\n",
       " ('any', 'DT'),\n",
       " ('woman', 'NN'),\n",
       " ('lead', 'VB'),\n",
       " ('me', 'PRP'),\n",
       " ('by', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('nose', 'JJ'),\n",
       " ('i', 'NN'),\n",
       " ('would', 'MD'),\n",
       " ('let', 'VB'),\n",
       " ('her', 'PRP'),\n",
       " ('know', 'VB'),\n",
       " ('that', 'IN'),\n",
       " ('as', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('living', 'NN'),\n",
       " ('comes', 'VBZ'),\n",
       " ('by', 'IN'),\n",
       " ('me', 'PRP'),\n",
       " ('the', 'DT'),\n",
       " ('way', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('getting', 'VBG'),\n",
       " ('it', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('my', 'PRP$'),\n",
       " ('affair', 'NN'),\n",
       " ('not', 'RB'),\n",
       " ('hers', 'NNS'),\n",
       " ('as', 'RB'),\n",
       " ('long', 'RB'),\n",
       " ('as', 'IN'),\n",
       " ('she', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('well', 'RB'),\n",
       " ('provided', 'VBN'),\n",
       " ('for', 'IN'),\n",
       " ('all', 'DT'),\n",
       " ('men', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('not', 'RB'),\n",
       " ('alike', 'IN'),\n",
       " ('and', 'CC'),\n",
       " ('i', 'VB'),\n",
       " ('confess', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('i', 'VBZ'),\n",
       " ('value', 'NN'),\n",
       " ('the', 'DT'),\n",
       " ('peace', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('happiness', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('home', 'NN'),\n",
       " ('more', 'RBR'),\n",
       " ('than', 'IN'),\n",
       " ('anything', 'NN'),\n",
       " ('else', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('i', 'NN'),\n",
       " ('would', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('like', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('engage', 'VB'),\n",
       " ('in', 'IN'),\n",
       " ('any', 'DT'),\n",
       " ('business', 'NN'),\n",
       " ('which', 'WDT'),\n",
       " ('i', 'VBP'),\n",
       " ('knew', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('source', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('constant', 'JJ'),\n",
       " ('pain', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('my', 'PRP$'),\n",
       " ('wife', 'NN'),\n",
       " ('but', 'CC'),\n",
       " ('what', 'WP'),\n",
       " ('right', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('woman', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('complain', 'VB'),\n",
       " ('if', 'IN'),\n",
       " ('she', 'PRP'),\n",
       " ('has', 'VBZ'),\n",
       " ('every', 'DT'),\n",
       " ('thing', 'NN'),\n",
       " ('she', 'PRP'),\n",
       " ('wants', 'VBZ'),\n",
       " ('i', 'NN'),\n",
       " ('would', 'MD'),\n",
       " ('let', 'VB'),\n",
       " ('her', 'PRP'),\n",
       " ('know', 'VB'),\n",
       " ('pretty', 'RB'),\n",
       " ('soon', 'RB'),\n",
       " ('who', 'WP'),\n",
       " ('holds', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('reins', 'NNS'),\n",
       " ('if', 'IN'),\n",
       " ('i', 'JJ'),\n",
       " ('had', 'VBD'),\n",
       " ('such', 'JJ'),\n",
       " ('an', 'DT'),\n",
       " ('unreasonable', 'JJ'),\n",
       " ('creature', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('deal', 'VB'),\n",
       " ('with', 'IN'),\n",
       " ('i', 'JJ'),\n",
       " ('think', 'VBP'),\n",
       " ('as', 'IN'),\n",
       " ('much', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('wife', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('any', 'DT'),\n",
       " ('man', 'NN'),\n",
       " ('but', 'CC'),\n",
       " ('i', 'JJ'),\n",
       " ('want', 'VBP'),\n",
       " ('her', 'PRP$'),\n",
       " ('to', 'TO'),\n",
       " ('know', 'VB'),\n",
       " ('her', 'PRP$'),\n",
       " ('place', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('i', 'NN'),\n",
       " ('know', 'VBP'),\n",
       " ('mine', 'NN'),\n",
       " ('what', 'WP'),\n",
       " ('do', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('call', 'VB'),\n",
       " ('her', 'PRP$'),\n",
       " ('place', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('call', 'VBP'),\n",
       " ('her', 'PRP$'),\n",
       " ('place', 'NN'),\n",
       " ('staying', 'VBG'),\n",
       " ('at', 'IN'),\n",
       " ('home', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('attending', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('her', 'PRP$'),\n",
       " ('own', 'JJ'),\n",
       " ('affairs', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('i', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('laboring', 'VBG'),\n",
       " ('man', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('would', 'MD'),\n",
       " ('never', 'RB'),\n",
       " ('want', 'VB'),\n",
       " ('my', 'PRP$'),\n",
       " ('wife', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('take', 'VB'),\n",
       " ('in', 'IN'),\n",
       " ('work', 'NN'),\n",
       " ('when', 'WRB'),\n",
       " ('a', 'DT'),\n",
       " ('woman', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('too', 'RB'),\n",
       " ('much', 'JJ'),\n",
       " ('on', 'IN'),\n",
       " ('hand', 'NN'),\n",
       " ('something', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('neglected', 'VBN'),\n",
       " ('now', 'RB'),\n",
       " ('i', 'VBP'),\n",
       " ('always', 'RB'),\n",
       " ('furnish', 'JJ'),\n",
       " ('my', 'PRP$'),\n",
       " ('wife', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('sufficient', 'JJ'),\n",
       " ('help', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('supply', 'VB'),\n",
       " ('every', 'DT'),\n",
       " ('want', 'NN'),\n",
       " ('but', 'CC'),\n",
       " ('how', 'WRB'),\n",
       " ('i', 'JJ'),\n",
       " ('get', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('living', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('where', 'WRB'),\n",
       " ('i', 'NN'),\n",
       " ('go', 'VBP'),\n",
       " ('and', 'CC'),\n",
       " ('what', 'WP'),\n",
       " ('company', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('keep', 'VBP'),\n",
       " ('is', 'VBZ'),\n",
       " ('my', 'PRP$'),\n",
       " ('own', 'JJ'),\n",
       " ('business', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('i', 'NN'),\n",
       " ('would', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('allow', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('best', 'JJS'),\n",
       " ('woman', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('interfere', 'VB'),\n",
       " ('i', 'NNS'),\n",
       " ('have', 'VBP'),\n",
       " ('often', 'RB'),\n",
       " ('heard', 'VBN'),\n",
       " ('women', 'NNS'),\n",
       " ('say', 'VBP'),\n",
       " ('that', 'IN'),\n",
       " ('they', 'PRP'),\n",
       " ('did', 'VBD'),\n",
       " ('not', 'RB'),\n",
       " ('care', 'VB'),\n",
       " ('what', 'WP'),\n",
       " ('their', 'PRP$'),\n",
       " ('husbands', 'NNS'),\n",
       " ('did', 'VBD'),\n",
       " ('so', 'RB'),\n",
       " ('that', 'IN'),\n",
       " ('they', 'PRP'),\n",
       " ('provided', 'VBD'),\n",
       " ('for', 'IN'),\n",
       " ('them', 'PRP'),\n",
       " ('and', 'CC'),\n",
       " ('i', 'VB'),\n",
       " ('think', 'VBP'),\n",
       " ('such', 'JJ'),\n",
       " ('conclusions', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('very', 'RB'),\n",
       " ('sensible', 'JJ'),\n",
       " ('well', 'RB'),\n",
       " ('john', 'NN'),\n",
       " ('i', 'NNS'),\n",
       " ('do', 'VBP'),\n",
       " ('not', 'RB'),\n",
       " ('think', 'VB'),\n",
       " ('so', 'RB'),\n",
       " ('i', 'JJ'),\n",
       " ('think', 'VBP'),\n",
       " ('a', 'DT'),\n",
       " ('woman', 'NN'),\n",
       " ('must', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('very', 'RB'),\n",
       " ('selfish', 'JJ'),\n",
       " ('if', 'IN'),\n",
       " ('all', 'DT'),\n",
       " ('she', 'PRP'),\n",
       " ('cares', 'VBZ'),\n",
       " ('for', 'IN'),\n",
       " ('her', 'PRP$'),\n",
       " ('husband', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('to', 'TO'),\n",
       " ('have', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('good', 'JJ'),\n",
       " ('provider', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('think', 'VBP'),\n",
       " ('her', 'PRP$'),\n",
       " ('husband', 'NN'),\n",
       " ('s', 'NN'),\n",
       " ('honor', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('welfare', 'NN'),\n",
       " ('should', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('as', 'IN'),\n",
       " ('dear', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('her', 'PRP$'),\n",
       " ('as', 'IN'),\n",
       " ('her', 'PRP$'),\n",
       " ('own', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('no', 'DT'),\n",
       " ('true', 'JJ'),\n",
       " ('woman', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('wife', 'NN'),\n",
       " ('can', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('indifferent', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('moral', 'JJ'),\n",
       " ('welfare', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('her', 'PRP$'),\n",
       " ('husband', 'NN'),\n",
       " ('neither', 'DT'),\n",
       " ('man', 'NN'),\n",
       " ('nor', 'CC'),\n",
       " ('woman', 'NN'),\n",
       " ('can', 'MD'),\n",
       " ('live', 'VB'),\n",
       " ('by', 'IN'),\n",
       " ('bread', 'JJ'),\n",
       " ('alone', 'RB'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('highest', 'JJS'),\n",
       " ('and', 'CC'),\n",
       " ('best', 'JJS'),\n",
       " ('sense', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('term', 'NN'),\n",
       " ('now', 'RB'),\n",
       " ('paul', 'VBZ'),\n",
       " ('don', 'NN'),\n",
       " ('t', 'NN'),\n",
       " ('go', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('preaching', 'VBG'),\n",
       " ('you', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('always', 'RB'),\n",
       " ('got', 'VBN'),\n",
       " ('some', 'DT'),\n",
       " ('moon', 'NN'),\n",
       " ('struck', 'VBD'),\n",
       " ('theories', 'NNS'),\n",
       " ('some', 'DT'),\n",
       " ('wild', 'VBP'),\n",
       " ('visionary', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('impracticable', 'JJ'),\n",
       " ('ideas', 'NNS'),\n",
       " ('which', 'WDT'),\n",
       " ('would', 'MD'),\n",
       " ('work', 'VB'),\n",
       " ('first', 'RB'),\n",
       " ('rate', 'NN'),\n",
       " ('if', 'IN'),\n",
       " ('men', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('angels', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('earth', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('paradise', 'NN'),\n",
       " ('now', 'RB'),\n",
       " ('don', 'VBZ'),\n",
       " ('t', 'NN'),\n",
       " ('be', 'VB'),\n",
       " ('so', 'RB'),\n",
       " ('serious', 'JJ'),\n",
       " ('old', 'JJ'),\n",
       " ('fellow', 'NN'),\n",
       " ('but', 'CC'),\n",
       " ('you', 'PRP'),\n",
       " ('know', 'VBP'),\n",
       " ('on', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('religion', 'NN'),\n",
       " ('business', 'NN'),\n",
       " ('you', 'PRP'),\n",
       " ('and', 'CC'),\n",
       " ('i', 'VB'),\n",
       " ('always', 'RB'),\n",
       " ('part', 'NN'),\n",
       " ('company', 'NN'),\n",
       " ('you', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('always', 'RB'),\n",
       " ('up', 'RB'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('clouds', 'NN'),\n",
       " ('while', 'IN'),\n",
       " ('i', 'JJ'),\n",
       " ('am', 'VBP'),\n",
       " ('trying', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('invest', 'VB'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('few', 'JJ'),\n",
       " ('acres', 'NNS'),\n",
       " ('or', 'CC'),\n",
       " ('town', 'NN'),\n",
       " ('lots', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('solid', 'JJ'),\n",
       " ('_terra', 'NNP'),\n",
       " ('firma_', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('would', 'MD'),\n",
       " ('your', 'PRP$'),\n",
       " ('hold', 'VB'),\n",
       " ('on', 'IN'),\n",
       " ('earthly', 'JJ'),\n",
       " ('possessions', 'NNS'),\n",
       " ('be', 'VB'),\n",
       " ('less', 'JJR'),\n",
       " ('firm', 'NN'),\n",
       " ('because', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('looked', 'VBD'),\n",
       " ('beyond', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('seen', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('unseen', 'JJ'),\n",
       " ('i', 'NN'),\n",
       " ('think', 'VBP'),\n",
       " ('it', 'PRP'),\n",
       " ('would', 'MD'),\n",
       " ('if', 'IN'),\n",
       " ('i', 'JJ'),\n",
       " ('let', 'VBP'),\n",
       " ('conscience', 'NN'),\n",
       " ('interfere', 'VB'),\n",
       " ('constantly', 'RB'),\n",
       " ('with', 'IN'),\n",
       " ('every', 'DT'),\n",
       " ('business', 'NN'),\n",
       " ('transaction', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('undertook', 'NN'),\n",
       " ('now', 'RB'),\n",
       " ('last', 'JJ'),\n",
       " ('week', 'NN'),\n",
       " ('you', 'PRP'),\n",
       " ('lost', 'VBD'),\n",
       " ('0', 'CD'),\n",
       " ('fair', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('square', 'NN'),\n",
       " ('because', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('would', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('foreclose', 'VB'),\n",
       " ('that', 'DT'),\n",
       " ('mortgage', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('smith', 'JJ'),\n",
       " ('s', 'JJ'),\n",
       " ('property', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('told', 'VBD'),\n",
       " ('you', 'PRP'),\n",
       " ('that', 'IN'),\n",
       " ('business', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('business', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('that', 'IN'),\n",
       " ('while', 'IN'),\n",
       " ('i', 'NN'),\n",
       " ('pitied', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('poor', 'JJ'),\n",
       " ('man', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('would', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('have', 'VB'),\n",
       " ('risked', 'VBN'),\n",
       " ('my', 'PRP$'),\n",
       " ('money', 'NN'),\n",
       " ('that', 'DT'),\n",
       " ('way', 'NN'),\n",
       " ('but', 'CC'),\n",
       " ('you', 'PRP'),\n",
       " ('said', 'VBD'),\n",
       " ('that', 'IN'),\n",
       " ('conscience', 'NN'),\n",
       " ('would', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('let', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('that', 'IN'),\n",
       " ('while', 'IN'),\n",
       " ('other', 'JJ'),\n",
       " ('creditors', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('gathering', 'VBG'),\n",
       " ('like', 'IN'),\n",
       " ('hungry', 'JJ'),\n",
       " ('vultures', 'NNS'),\n",
       " ('around', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('poor', 'JJ'),\n",
       " ('man', 'NN'),\n",
       " ('you', 'PRP'),\n",
       " ('would', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('join', 'VB'),\n",
       " ('with', 'IN'),\n",
       " ('them', 'PRP'),\n",
       " ('and', 'CC'),\n",
       " ('that', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('did', 'VBD'),\n",
       " ('not', 'RB'),\n",
       " ('believe', 'VB'),\n",
       " ('in', 'IN'),\n",
       " ('striking', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('man', 'NN'),\n",
       " ('when', 'WRB'),\n",
       " ('he', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('down', 'RB'),\n",
       " ('now', 'RB'),\n",
       " ('paul', 'VBZ'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('business', 'NN'),\n",
       " ('man', 'NN'),\n",
       " ('if', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('want', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('succeed', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('got', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('look', 'VB'),\n",
       " ('at', 'IN'),\n",
       " ('business', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('practical', 'JJ'),\n",
       " ('common', 'JJ'),\n",
       " ('sense', 'NN'),\n",
       " ('way', 'NN'),\n",
       " ('smith', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('dead', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('where', 'WRB'),\n",
       " ('is', 'VBZ'),\n",
       " ('your', 'PRP$'),\n",
       " ('money', 'NN'),\n",
       " ('now', 'RB'),\n",
       " ('apparently', 'RB'),\n",
       " ('lost', 'VBN'),\n",
       " ('but', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('time', 'NN'),\n",
       " ('may', 'MD'),\n",
       " ('come', 'VB'),\n",
       " ('when', 'WRB'),\n",
       " ('i', 'JJ'),\n",
       " ('shall', 'MD'),\n",
       " ('feel', 'VB'),\n",
       " ('that', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('best', 'JJS'),\n",
       " ('investments', 'NNS'),\n",
       " ('i', 'VB'),\n",
       " ('ever', 'RB'),\n",
       " ('made', 'VBN'),\n",
       " ('stranger', 'NN'),\n",
       " ('things', 'NNS'),\n",
       " ('than', 'IN'),\n",
       " ('that', 'DT'),\n",
       " ('have', 'VBP'),\n",
       " ('happened', 'VBN'),\n",
       " ('i', 'JJ'),\n",
       " ('confess', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('i', 'NN'),\n",
       " ('felt', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('loss', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('it', 'PRP'),\n",
       " ('has', 'VBZ'),\n",
       " ('somewhat', 'RB'),\n",
       " ('cramped', 'VBN'),\n",
       " ('my', 'PRP$'),\n",
       " ('business', 'NN'),\n",
       " ('yet', 'RB'),\n",
       " ('if', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('do', 'VB'),\n",
       " ('over', 'RP'),\n",
       " ('again', 'RB'),\n",
       " ('i', 'JJ'),\n",
       " ('don', 'VBP'),\n",
       " ('t', 'JJ'),\n",
       " ('think', 'VBP'),\n",
       " ('that', 'IN'),\n",
       " ('i', 'NN'),\n",
       " ('would', 'MD'),\n",
       " ('act', 'VB'),\n",
       " ('differently', 'RB'),\n",
       " ('and', 'CC'),\n",
       " ('when', 'WRB'),\n",
       " ('i', 'JJ'),\n",
       " ('believe', 'VBP'),\n",
       " ('that', 'IN'),\n",
       " ('smith', 'NN'),\n",
       " ('s', 'JJ'),\n",
       " ('death', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('hurried', 'VBN'),\n",
       " ('on', 'IN'),\n",
       " ('by', 'IN'),\n",
       " ('anxiety', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('business', 'NN'),\n",
       " ('troubles', 'NNS'),\n",
       " ('while', 'IN'),\n",
       " ('i', 'NN'),\n",
       " ('regret', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('loss', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('my', 'PRP$'),\n",
       " ('money', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('am', 'VBP'),\n",
       " ('thankful', 'JJ'),\n",
       " ('that', 'IN'),\n",
       " ('i', 'NN'),\n",
       " ('did', 'VBD'),\n",
       " ('not', 'RB'),\n",
       " ('press', 'VB'),\n",
       " ('my', 'PRP$'),\n",
       " ('claim', 'NN'),\n",
       " ('sour', 'JJ'),\n",
       " ('grapes', 'NNS'),\n",
       " ('but', 'CC'),\n",
       " ('you', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('right', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('put', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('best', 'JJS'),\n",
       " ('face', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('matters', 'NNS'),\n",
       " ('no', 'DT'),\n",
       " ('if', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " ('were', 'VBD'),\n",
       " ('to', 'TO'),\n",
       " ('do', 'VB'),\n",
       " ('over', 'RP'),\n",
       " ('again', 'RB'),\n",
       " ('i', 'JJ'),\n",
       " ('never', 'RB'),\n",
       " ('would', 'MD'),\n",
       " ('push', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('struggling', 'VBG'),\n",
       " ('man', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('wall', 'NN'),\n",
       " ('when', 'WRB'),\n",
       " ('he', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('making', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('desperate', 'JJ'),\n",
       " ('fight', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('his', 'PRP$'),\n",
       " ('wife', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('little', 'JJ'),\n",
       " ('ones', 'NNS'),\n",
       " ('well', 'RB'),\n",
       " ('paul', 'IN'),\n",
       " ('we', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('both', 'DT'),\n",
       " ('young', 'JJ'),\n",
       " ('men', 'NNS'),\n",
       " ('just', 'RB'),\n",
       " ('commencing', 'VBG'),\n",
       " ('life', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('my', 'PRP$'),\n",
       " ('motto', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('to', 'TO'),\n",
       " ('look', 'VB'),\n",
       " ('out', 'RP'),\n",
       " ('for', 'IN'),\n",
       " ('number', 'NN'),\n",
       " ('0', 'CD'),\n",
       " ('and', 'CC'),\n",
       " ('you', 'PRP'),\n",
       " ('oh', 'VBP'),\n",
       " ('i', 'JJ'),\n",
       " ('believe', 'VBP'),\n",
       " ('in', 'IN'),\n",
       " ('lending', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('helping', 'VBG'),\n",
       " ('hand', 'NN'),\n",
       " ('so', 'RB'),\n",
       " ('do', 'VBP'),\n",
       " ('i', 'VB'),\n",
       " ('when', 'WRB'),\n",
       " ('i', 'NN'),\n",
       " ('can', 'MD'),\n",
       " ('make', 'VB'),\n",
       " ('every', 'DT'),\n",
       " ('corner', 'NN'),\n",
       " ('out', 'IN'),\n",
       " ('to', 'TO'),\n",
       " ('my', 'PRP$'),\n",
       " ('advantage', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('believe', 'VBP'),\n",
       " ('in', 'IN'),\n",
       " ('every', 'DT'),\n",
       " ('man', 'NN'),\n",
       " ('looking', 'VBG'),\n",
       " ('out', 'RP'),\n",
       " ('for', 'IN'),\n",
       " ('himself', 'PRP'),\n",
       " ('you', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('see', 'VB'),\n",
       " ('by', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('dialogue', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('characters', 'NNS'),\n",
       " ('i', 'VBP'),\n",
       " ('here', 'RB'),\n",
       " ('introduce', 'NNS'),\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Ouvrir le fichier\n",
    "with open('sowing-and-reaping.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Clean text\n",
    "text.strip()\n",
    "text = text.lower()\n",
    "text = replace_pattern_sub(digit_regex, '0', text)\n",
    "\n",
    "# Tokenize\n",
    "tokens = regexpTokenizer.tokenize(text)\n",
    "\n",
    "# POS tagging\n",
    "pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ef8a22-f9d3-4ddc-a8e2-f27bf660f7b8",
   "metadata": {},
   "source": [
    "## Racinisation/Lemmatisation\n",
    "\n",
    "La racinisation et la lemmatisation consistent toutes deux à supprimer les affixes morphologiques des mots. \n",
    "\n",
    "La racinisation consiste à tronquer un mot de toute déclinaison, inflexions et dérivations pour n'obtenir que la racine. En traitement automatique des langues, on opère la racinisation, souvent, en supprimant une partie de la fin du mot. La taille de la fin du mot dépend de la méthode de racinisation utilisée. La taille peut être sous-estimée ou sur-estimée. En conséquence la racine pourrait ne pas exister dans le dictionnaire de la langue concernée.\n",
    "\n",
    "La lemmatisation consiste à réduire un mot à sa forme de base, quels que soient ses déclinaisons et ses accords. La forme de base dépend de la langue. En français, on choisit l'infinitif ou le genre, mais pas systématiquement. \n",
    "\n",
    "Nous procédons à la racinisation et la lemmatisation parce que, souvent, nous nous soucions davantage du contenu essentiel du mot. Par exemple, on ne soucie pas d'un verbe à la troisième personne du présent, ou du futur mais plutôt de son sens. Néanmoins, si la tâche TAL nécessite de connaître le temps du verbe, la lemmatisation doit être personnalisée. La même remarque s'applique à la racinisation.\n",
    "\n",
    "NLTK fournit de nombreux algorithmes pour la racinisation et la lemmatisation. Des bases de références sont les algorithmes de racinisation `PorterStemmer` et `SnowballStemmer` et l'algorithme de lemmatisation `WordNetLemmatizer`.\n",
    "\n",
    "Soit les mots suivants walks, eating, corrected, appliquer l'une des deux algorithmes de racinisation. Les racines obtenues sont-elles valides linguistiquement (autrement dit, ont elles unt existence réelle dans la langue anglaise?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66485ab2-267f-4a7e-80c3-3af366e839bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['walk', 'eat', 'correct']\n"
     ]
    }
   ],
   "source": [
    "words = ['walks', 'eating', 'corrected']\n",
    "\n",
    "# Racinisation avec PorterStemmer\n",
    "porter = nltk.stem.PorterStemmer()\n",
    "porter_stems = [porter.stem(word) for word in words]\n",
    "print(porter_stems)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62fc0fc6",
   "metadata": {},
   "source": [
    "Les mots ont un sens dans la langue anglaise après racinisation : ['walk', 'eat', 'correct']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cdf5e7-0f5c-48b9-8afa-b8ced897d831",
   "metadata": {},
   "source": [
    "Soit les mots suivants mice, wolves, continued, women, theses, crises, criteria, appliquer les deux méthodes de racinisations. Qu'observez-vous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "869e3bab-9531-461d-bf51-bb00ab588df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Racinisation avec PorterStemmer ['mice', 'wolv', 'continu', 'women', 'these', 'crise', 'criteria']\n",
      "Racinisation avec SnowballStemmer ['mice', 'wolv', 'continu', 'women', 'these', 'crise', 'criteria']\n"
     ]
    }
   ],
   "source": [
    "words = ['mice', 'wolves', 'continued', 'women', 'theses', 'crises', 'criteria']\n",
    "\n",
    "# Racinisation avec PorterStemmer\n",
    "porter_stems = [porter.stem(word) for word in words]\n",
    "print(\"Racinisation avec PorterStemmer\", porter_stems)\n",
    "\n",
    "# Racinisation avec SnowballStemmer\n",
    "snowball = nltk.stem.SnowballStemmer('english')\n",
    "snowball_stems = [snowball.stem(word) for word in words]\n",
    "print(\"Racinisation avec SnowballStemmer\", snowball_stems)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38b56cad",
   "metadata": {},
   "source": [
    "Les deux méthodes de racinisations sont sensiblements identiques.\n",
    "Cependant, nous perdons le sens de certains mots lorsqu'on l'applique sur des noms, notamment 'wolves' qui devient 'wolv'\n",
    "La racinisation récupère seulement la racine d'un mot.\n",
    "\n",
    "Les mots ne sont pas mis au singulier ou ne sont pas des mots de la langue anglaise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da75802c-4a2e-40dd-8231-8ee4d30909c4",
   "metadata": {},
   "source": [
    "Appliquer un lemmatiseur sur cette même liste. Qu'observez-vous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbae899d-777d-4891-8c7a-6c685d76a2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Julien\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Julien\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatizer avec WordNet ['mouse', 'wolf', 'continued', 'woman', 'thesis', 'crisis', 'criterion']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "words = ['mice', 'wolves', 'continued', 'women', 'theses', 'crises', 'criteria']\n",
    "\n",
    "# Lemmatizer avec WordNet\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "print(\"Lemmatizer avec WordNet\", lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5997df05-eb7d-4b11-8464-2db290a89a49",
   "metadata": {},
   "source": [
    "Les mots ont été transformés par leur singulier sauf 'continued' qui est resté le même."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7773a30b-4485-4234-a335-fe21b665d51d",
   "metadata": {},
   "source": [
    "Que s'est-il passé avec le terme `continued`? Il est parfois nécessaire de fournir au lemmatiseur une étiquette morpho-syntaxique pour l'aider à résoudre les cas ambigus. WordNetLemmatizer a un paramètre `pos` permettant de préciser la classe du mot. Parmi les valeurs possibles de ce paramètre sont:\n",
    "- \"n\" pour les noms,\n",
    "- \"v\" pour les verbes,\n",
    "- \"a\" pour les adjectifs, \n",
    "- \"r\" pour les adverbes\n",
    "\n",
    "Utilisez ce paramètre pour résoudre le cas de `continued`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a902f027-9ed2-4d86-9a0c-38e6048f5706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatizer de 'continued' :  continue\n"
     ]
    }
   ],
   "source": [
    "word = 'continued'\n",
    "\n",
    "# Lemmatizer avec WordNet\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "lemmatized_continued = lemmatizer.lemmatize(word, pos='v')\n",
    "print(\"Lemmatizer de 'continued' : \", lemmatized_continued)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3a2cc3-6192-4c9b-b55e-90a6b023c3ee",
   "metadata": {},
   "source": [
    "Utiliser ce paramètre pour le terme `leaves` en tant que verbe et nom. Qu'observez-vous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2b7d7bc-7210-42e1-a6d5-48020791cc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatizer de 'leaves' en tant que verbe :  leave\n",
      "Lemmatizer de 'leaves' en tant que nom :  leaf\n"
     ]
    }
   ],
   "source": [
    "word = 'leaves'\n",
    "\n",
    "# Lemmatizer avec WordNet\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "lematized_v = lemmatizer.lemmatize(word, pos='v')\n",
    "print(\"Lemmatizer de 'leaves' en tant que verbe : \", lematized_v)\n",
    "lematized_n = lemmatizer.lemmatize(word, pos='n')\n",
    "print(\"Lemmatizer de 'leaves' en tant que nom : \", lematized_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1276c09b-4798-4a62-a0ba-730e998cb99b",
   "metadata": {},
   "source": [
    "Le mot 'leaves' correspond à la troisième personne du singulier du verbe 'leave' et au pluriel du mot 'leaf'. Il peut être interpreté de deux façon différentes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b066985-bf5b-406e-9217-592166c8f55e",
   "metadata": {},
   "source": [
    "Spacy est une bibliothèque dédiée au traitement automatique des langues. Elle propose un lemmatiseur basé sur des modèles d'apprentissage automatique pré-entraînés capables de déterminer étiquettes morpho-syntaxiques et produire des lemmes par un simple appel de fonction, contrairement au lemmatiseur WordNetLemmatize, où les étiquettes morpho-syntaxiques doivent être explicitement fournies.\n",
    "\n",
    "Nous pouvons installer Spacy et télécharger le modèle `en` pour la langue anglaise en exécutant la commande suivante en ligne de commande: \n",
    "\n",
    "pip install spacy && python -m spacy download en\n",
    "\n",
    "Charger le modèle `en` que vous affecterez à la variable `nlp`. Cette variable est, en réalité, une fonction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0711a9fc-1a67-490f-a3ad-ed6a1da235b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Charger le modèle 'en' pour la langue anglaise\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f59acd8c-cd7f-4393-943a-fc1ea4bc7e0e",
   "metadata": {},
   "source": [
    "Appelez cette fonction sur la phrase suivante : She said she was a \"fighter not a quitter\" as she tried to reassert authority over the fraught ranks of her Conservative Party on Wednesday, amid growing media reports that momentum was building to oust her.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9d841df-934c-4c13-b081-c2bf87e1beaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She PRON\n",
      "said VERB\n",
      "she PRON\n",
      "was AUX\n",
      "a DET\n",
      "' PUNCT\n",
      "fighter NOUN\n",
      "not PART\n",
      "a DET\n",
      "quitter NOUN\n",
      "' PUNCT\n",
      "as SCONJ\n",
      "she PRON\n",
      "tried VERB\n",
      "to PART\n",
      "reassert VERB\n",
      "authority NOUN\n",
      "over ADP\n",
      "the DET\n",
      "fraught ADJ\n",
      "ranks NOUN\n",
      "of ADP\n",
      "her PRON\n",
      "Conservative PROPN\n",
      "Party PROPN\n",
      "on ADP\n",
      "Wednesday PROPN\n",
      ", PUNCT\n",
      "amid ADP\n",
      "growing VERB\n",
      "media NOUN\n",
      "reports NOUN\n",
      "that SCONJ\n",
      "momentum NOUN\n",
      "was AUX\n",
      "building VERB\n",
      "to PART\n",
      "oust VERB\n",
      "her PRON\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "text = \"She said she was a 'fighter not a quitter' as she tried to reassert authority over the fraught ranks of her Conservative Party on Wednesday, amid growing media reports that momentum was building to oust her.\"\n",
    "\n",
    "nlp_output = nlp(text)\n",
    "\n",
    "# Afficher le texte et le POS tag pour chaque token\n",
    "for token in nlp_output:\n",
    "    print(token.text, token.pos_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ae94bf-fb6f-4106-b156-24cb90b7eb28",
   "metadata": {},
   "source": [
    "### Défi\n",
    "\n",
    "Utilisez les algorithmes de racinisation et les algorithmes de lemmatisation sur chacun des tweets (voir notebook précédent). Vous devez au préalable avoir segmenté les tweets en phrases et supprimé les mots vides. A noter que vous devez utiliser, avec le lemmatiseur WordNetLemmatize, un étiquetteur morpho-syntaxique sur une liste de tokens issue d'une phrase. \n",
    "\n",
    "Identifiez les mots uniques des résultats de chacun des quatre algorithmes puis calculer le nombre de termes communs pour chaque paire des résultats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16b4e48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sur 10000 tweets, voici la comparaison des mots communs entre : \n",
      "Spacy - WordNet :  0\n",
      "Spacy - SnowBall :  0\n",
      "Spacy - Porter :  0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def unique_words(tableau):\n",
    "    unique = set()\n",
    "    for ligne in tableau:\n",
    "        for mot in ligne:\n",
    "            unique.add(mot)\n",
    "    return list(unique)\n",
    "\n",
    "tweets = pd.read_csv('airline_tweets.csv', encoding='utf-8')\n",
    "\n",
    "# On transforme les tweets en token\n",
    "tweets_token = tweets['text'][:10000].apply(nltk.word_tokenize)\n",
    "\n",
    "tweets_clean = []\n",
    "for tweets in tweets_token:\n",
    "    words_filter = [word for word in tweets if word.lower() not in stop_words]\n",
    "    tweets_clean.append(words_filter)\n",
    "\n",
    "\n",
    "# On utilise les algos de lemmatisation et de racinisation (SnowBall, Porter, Spacy et WordNet)\n",
    "wordNet = list()\n",
    "snowball = list()\n",
    "porter = list()\n",
    "spacy = []\n",
    "for tweet in tweets_clean:\n",
    "    wordNet.append([nltk.WordNetLemmatizer().lemmatize(word) for word in tweet])\n",
    "    snowball.append([nltk.SnowballStemmer('english').stem(word) for word in tweet])\n",
    "    porter.append([nltk.PorterStemmer().stem(word) for word in tweet])\n",
    "    spacy.append(nlp(' '.join(tweet)))\n",
    "\n",
    "# On affiche les résultats\n",
    "# print(\"WordNet : \", wordNet)\n",
    "# print(\"Snowball : \", snowball)\n",
    "# print(\"Porter : \", porter)\n",
    "# print(\"Spacy : \", spacy)\n",
    "\n",
    "# Création d'un ensemble de mots uniques pour chaque tableau de phrases\n",
    "spacyTweets = set(unique_words(spacy))\n",
    "wordNetTweets = set(unique_words(wordNet))\n",
    "snowBallTweets = set(unique_words(snowball))\n",
    "porterTweets = set(unique_words(porter))\n",
    "\n",
    "\n",
    "# Calcul de l'intersection des ensembles de mots entre spacy et les autres\n",
    "mots_communs_spacy_wordnet = spacyTweets.intersection(wordNetTweets)\n",
    "mots_communs_spacy_snowball = spacyTweets.intersection(snowBallTweets)\n",
    "mots_communs_spacy_porter = spacyTweets.intersection(porterTweets)\n",
    "\n",
    "# Affichage du nombre de mots communs\n",
    "print(\"Sur \" + str(len(tweets_token)) + \" tweets, voici la comparaison des mots communs entre : \")\n",
    "print(\"Spacy - WordNet : \", len(mots_communs_spacy_wordnet))\n",
    "print(\"Spacy - SnowBall : \", len(mots_communs_spacy_snowball))\n",
    "print(\"Spacy - Porter : \", len(mots_communs_spacy_porter))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a87e323-0de6-43ef-9cf4-e5589d1f4355",
   "metadata": {},
   "source": [
    "## Reconnaissance d'entités nommées(REN)\n",
    "\n",
    "Lorsque nous lisons et traitons des phrases, nous avons tendance à identifier d'abord les acteurs clés de la phrase (par exemple, les personnes, les lieux et les organisations). Cette classification nous aide à décomposer la phrase en entités et à donner un sens à la sémantique de la phrase. La reconnaissance d'entités nommées imite le même comportement et est utilisée pour classer les entités nommées (ou noms propres) dans un texte donné. Les applications de cette catégorisation sont largement utilisées dans l'industrie. L'une des applications réelles de REN est le résumé de texte. Celui-ci consiste à analyser des documents textuels et à résumer ceux-ci en identifiant les entités clés du document. Un cas d'utilisation populaire est la catégorisation de CV, dans lequel le REN traite un grand nombre de CV et met en évidence les entités clés telles que le nom, l'institution et les compétences, ce qui facilite une évaluation rapide. \n",
    "\n",
    "Appelez la fonction `nlp` sur la phrase précédente \"She said she was...\". Vous assignez le résultat dans une variable appelée `res`. Cette dernière a un attribut ents correspondant à une liste d'objets. Dans l'objet, vous récupérer l'entité nommée avec l'attribut label_ et le mot ou composé de mots associé avec l'attribut text. \n",
    "\n",
    "Créez une liste de tuples où chacune contient les attributs test et label_.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d73b3f6-c1f8-4b21-92b5-29c75bc7df50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ORG', 'Conservative Party'), ('DATE', 'Wednesday')]\n"
     ]
    }
   ],
   "source": [
    "resultat = nlp('She said she was a \"fighter not a quitter\" as she tried to reassert authority over the fraught ranks of her Conservative Party on Wednesday, amid growing media reports that momentum was building to oust her.')\n",
    "\n",
    "\n",
    "tuples = []\n",
    "\n",
    "# On récupère dans resultat les entités label_ et text\n",
    "for entite in resultat.ents:\n",
    "    tuples.append((entite.label_, entite.text))\n",
    "\n",
    "# On affiche les résultats\n",
    "print(tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76e1186-c782-40c8-addd-8f6d3e95db72",
   "metadata": {},
   "source": [
    "## Défi\n",
    "\n",
    "Reprenez les commentaires Amazon pre-traités et appliquez REN. Puis organisez les entités nommées par type (par exemple, organisation, personne...). Les types sont fournis dans les attributs label_. \n",
    "\n",
    "Calculez pour chaque type, les 10 premiers textes les plus fréquents. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f6dd24a2-4f64-41b6-aa7a-909835ed3b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type d'entité : DATE\n",
      "[('christmas', 2), ('halloween', 2), ('around a few centuries', 1), ('only two weeks', 1), ('more than two years', 1), ('july', 1), ('all these years', 1), ('several years', 1), ('/>two years ago', 1), ('decades', 1)]\n",
      "------------------------------\n",
      "Type d'entité : GPE\n",
      "[('vermont', 2), ('c.s', 1), ('pennsylvania', 1), ('the united states', 1), ('mexico', 1), ('america', 1), ('newton', 1), ('texas', 1), ('nirvana', 1)]\n",
      "------------------------------\n",
      "Type d'entité : QUANTITY\n",
      "[('six pounds', 2), ('five pound', 1), ('a half cup', 1), ('several hundred mile', 1)]\n",
      "------------------------------\n",
      "Type d'entité : ORDINAL\n",
      "[('second', 4), ('first', 3), ('firstly', 1), ('third', 1)]\n",
      "------------------------------\n",
      "Type d'entité : CARDINAL\n",
      "[('one', 7), ('two', 3), ('six', 2), ('three', 2), ('almost half', 1), ('five', 1), ('zero', 1), ('half', 1), ('though.<br', 1)]\n",
      "------------------------------\n",
      "Type d'entité : ORG\n",
      "[('mccann', 8), ('maple & brown sugar', 3), ('y & s candies, inc.', 2), ('/>mccann', 2), ('blue raspberry', 1), ('drinker!).<br', 1), ('quaker oats', 1), ('apple cider jelly', 1), ('petco', 1)]\n",
      "------------------------------\n",
      "Type d'entité : PERSON\n",
      "[('jack russell', 2), ('DIGIT.DIGIT feet', 1), ('DIGIT kg', 1), ('jerry reith', 1), ('cranberry horseradish', 1), ('endurolyte', 1), ('DIGIT.DIGIT', 1), ('DIGIT pound bags', 1), ('DIGIT+', 1), ('vanilla bean', 1)]\n",
      "------------------------------\n",
      "Type d'entité : TIME\n",
      "[('every morning', 2), ('less than a minute', 1), ('two or three minutes', 1), ('seconds', 1), ('the other morning', 1), ('half an hour', 1), ('under three minutes', 1), ('about one minute and', 1), ('twenty-seven seconds', 1), ('night', 1)]\n",
      "------------------------------\n",
      "Type d'entité : MONEY\n",
      "[('$DIGIT.DIGIT cents', 1), ('almost $DIGIT.DIGIT', 1), ('about $', 1)]\n",
      "------------------------------\n",
      "Type d'entité : NORP\n",
      "[('mexican', 1), ('/>these', 1), ('albanese', 1), ('english', 1)]\n",
      "------------------------------\n",
      "Type d'entité : LOC\n",
      "[('mango', 2)]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "NB_FICHIER = 5\n",
    "NB_COMMENTAIRES_TRAITES = 100\n",
    "\n",
    "# Récupération des fichiers amazon\n",
    "dossier = \"./amazon\"\n",
    "header = []  # initial value for header\n",
    "\n",
    "contents = []\n",
    "for i, file_name in enumerate(os.listdir(dossier)[:NB_FICHIER]):\n",
    "    file_path = os.path.join(dossier, file_name)\n",
    "    if not header:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')\n",
    "        header = df.columns.tolist()\n",
    "    else:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8', header=None, names=header)\n",
    "    contents.append(df['Text'])\n",
    "contents = pd.concat(contents).tolist()\n",
    "\n",
    "# Nettoyage de chaque valeurs dans la liste contents :\n",
    "contents = [clean_text(text) for text in contents]\n",
    "\n",
    "########################################\n",
    "\n",
    "# On applique REN pour récupérer les entités nommées et les organiser par type graçe à l'attribut label_\n",
    "res = [nlp(text) for text in contents[:NB_COMMENTAIRES_TRAITES]]\n",
    "entities_by_type = {}\n",
    "for ents in res:\n",
    "    for ent in ents.ents:\n",
    "        if ent.label_ not in entities_by_type:\n",
    "            entities_by_type[ent.label_] = []\n",
    "        entities_by_type[ent.label_].append(ent.text)\n",
    "\n",
    "# Pour chaque type d'entité, on calcule les 10 entités les plus fréquentes, de la même manière qu'avec les mots question 1\n",
    "for entity_type in entities_by_type:\n",
    "    entity_counts = Counter(entities_by_type[entity_type])\n",
    "    most_frequent_entities = entity_counts.most_common(10)\n",
    "    print(f\"Type d'entité : {entity_type}\")\n",
    "    print(most_frequent_entities)\n",
    "    print(\"------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
