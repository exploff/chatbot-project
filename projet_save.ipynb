{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet ChatBot\n",
    "\n",
    "## Sommaire\n",
    "\n",
    "- Rappel\n",
    "- Problématique\n",
    "- Sujet\n",
    "- Outils\n",
    "- Modalités\n",
    "- Ressources\n",
    "\n",
    "## Rappel\n",
    "\n",
    "<p>\n",
    "    Lors des 5 travaux précédents, vous avez-vu les bases de la NLP, <br/>\n",
    "    vous avez exploré les différentes manières de traiter du texte et <br/>\n",
    "    vous avez mis en place votre premier chatbot simpliste. \n",
    "</p>\n",
    "\n",
    "## Problématique\n",
    "\n",
    "<p>Le but de ce projet et de mettre en place un chatbot de type OK Google, Siri, Alexa,..</p>\n",
    "<p>Dans ce projet vous aller créer un certain nombre de fonctions qui seront appliquées par un algorithme de reconnaissance vocale.<br>\n",
    "Le programme prend en entrée un texte enregistré à l'aide d'un microphone et en sortie exécute une fonction adéquate à la demande énoncée</p>\n",
    "\n",
    "<i><u>Exemple :</u><br>\n",
    "Moi: \"Montre moi un chat\"<br>\n",
    "ChatBot: \"Ok je vous montre un chat\" => Ouvre un navigateur avec une photo de chat.\n",
    "</i>\n",
    "\n",
    "## Sujet\n",
    "En vous appuyant sur les TP précédemment vu en cours et les outils fournis votre chatbot devra être capable de :\n",
    "- Prendre une entrée microphone\n",
    "- Adapter la langue du chatbot en fonction de la demande en français ou en anglais\n",
    "- Exécuter des fonctions macros à l'aide du fichier de configuration fourni\n",
    "- Pouvoir exécuter au moins 4 fonctions distinctes\n",
    "- Si la demande ne figure pas dans le fichier de configuration: Utiliser un chatbot extérieur afin de tenter de répondre à la demande\n",
    "\n",
    "Fonctionnalités : \n",
    "- Ouvrir un navigateur pour la recherche en général (musique, etc...)\n",
    "- Donner la météo, ou autre chose (API)\n",
    "- Répondre à l'oral\n",
    "- Répondre à une problématique médicale\n",
    "\n",
    "<b>Un soin tout particulié sera donné à la conception</b>\n",
    "\n",
    "> Soigner l'ergonomie\n",
    "\n",
    "> Soigner la qualité du code\n",
    "\n",
    "## Outils\n",
    "Afin de vous aider à réaliser ce projet, je vous invite à regarder les librairies suivantes:\n",
    "- SpeechRecognition<br>\n",
    "https://pypi.org/project/SpeechRecognition/\n",
    "- transformers<br>\n",
    "https://pypi.org/project/transformers/2.1.0/\n",
    "- gTTS<br>\n",
    "https://pypi.org/project/gTTS/\n",
    "\n",
    "## Modalités\n",
    "- Travail en groupe de 2 ou 3\n",
    "- Soutenance <b>technique</b> de fin de projet de 15 minutes avec rapport de 10 pages minimum\n",
    "- A rendre avant le 03.04.2023 23:59\n",
    "- Rapport à rendre avant le 10.04.2023 23:59\n",
    "- Sous le nom: nGroupe_nom1_nom2_nom3_chatbot.ipynb\n",
    "\n",
    "## Ressources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_phrases = [\n",
    "    \"Can you look something up on Google for me?\",\n",
    "    \"Can you do a Google search for me?\",\n",
    "    \"Can you help me find something on Google?\",\n",
    "    \"I need to look something up on Google, can you help me?\",\n",
    "    \"I'm looking for information on a topic, can you Google it for me?\",\n",
    "    \"I can't find the information I need, can you Google it?\",\n",
    "    \"I want to learn more about a topic, can you do a Google search for me?\",\n",
    "    \"I want to find relevant articles on a topic, can you help me search on Google?\",\n",
    "    \"I don't know how to search for information on Google, can you help me?\",\n",
    "    \"I'm looking for documents on a topic, can you do a Google search for me?\",\n",
    "    \"Can you help me find the answer to a question by Googling it?\",\n",
    "    \"I want to find the best results for a topic, can you help me search on Google?\",\n",
    "    \"I need to find some references on a topic, can you do a Google search for me?\",\n",
    "    \"I'm curious about something, can you Google it for me?\",\n",
    "    \"I'm stuck and need help finding something, can you search for it on Google?\",\n",
    "    \"I'm trying to research something, can you help me by searching on Google?\",\n",
    "    \"I want to find some examples of something, can you Google it for me?\",\n",
    "    \"I need to fact-check something, can you help me by searching on Google?\",\n",
    "    \"I'm looking for a specific piece of information, can you do a Google search for me?\",\n",
    "    \"I'm trying to find the source of a quote, can you help me search on Google?\",\n",
    "    \"Can you help me find a credible source on a topic by Googling it?\",\n",
    "    \"I want to find some statistics on a topic, can you do a Google search for me?\",\n",
    "    \"I'm trying to find a specific website, can you help me by searching on Google?\",\n",
    "    \"I need to find some images related to a topic, can you Google it for me?\",\n",
    "    \"I'm looking for a video on a topic, can you help me find it by searching on Google?\",\n",
    "    \"I'm trying to find a review of something, can you help me by Googling it?\",\n",
    "    \"I need to find some customer feedback on a product, can you help me by searching on Google?\",\n",
    "    \"I want to find the history of something, can you do a Google search for me?\",\n",
    "    \"I'm trying to find a biography of someone, can you help me by searching on Google?\",\n",
    "    \"Can you help me find a news article on a topic by Googling it?\",\n",
    "    \"I'm looking for some tutorials on a topic, can you help me find them by searching on Google?\",\n",
    "    \"I want to find some research papers on a topic, can you do a Google search for me?\",\n",
    "    \"I need to find some case studies on a topic, can you help me by searching on Google?\",\n",
    "    \"I'm trying to find a white paper on a topic, can you help me by Googling it?\",\n",
    "    \"I want to find some blogs on a topic, can you do a Google search for me?\",\n",
    "    \"I'm looking for some forums on a topic, can you help me find them by searching on Google?\",\n",
    "    \"I'm trying to find a discussion thread on a topic, can you help me by searching on Google?\",\n",
    "    \"I need to find some podcasts on a topic, can you help me by Googling\"\n",
    "]\n",
    "\n",
    "\n",
    "actualite_phrases = [\n",
    "    \"Can you give me the latest news?\",\n",
    "    \"What's new in the world today?\",\n",
    "    \"I want to know what's happening in the news\",\n",
    "    \"Can you tell me what's going on in the world?\",\n",
    "    \"Can you give me the headlines?\",\n",
    "    \"What's happening in the world right now?\",\n",
    "    \"What's the latest news update?\",\n",
    "    \"Can you give me the breaking news?\",\n",
    "    \"I want to stay informed, what's the latest news?\",\n",
    "    \"What's the latest news from the sports world?\",\n",
    "    \"What's the update on the latest technology news?\",\n",
    "    \"Can you tell me more about the latest business news?\",\n",
    "    \"What's happening in the entertainment world?\",\n",
    "    \"I'm curious about the latest health news, what's the update?\",\n",
    "    \"What's the current state of the fashion industry?\",\n",
    "    \"Can you give me any updates on the latest environmental news?\",\n",
    "    \"What's the latest news from the education world?\",\n",
    "    \"What's the update on the latest social media trends?\",\n",
    "    \"Can you tell me more about the latest developments in the art world?\",\n",
    "    \"What's the current state of the travel industry?\",\n",
    "    \"Can you give me an update on the latest technology releases?\",\n",
    "    \"What's the latest news on the stock market?\",\n",
    "    \"What's the update on the latest political scandals?\",\n",
    "    \"Can you tell me more about the latest gaming news?\",\n",
    "    \"What are the latest developments in the automotive industry?\",\n",
    "    \"What's the current state of the real estate market?\",\n",
    "    \"Can you give me an update on the latest celebrity news?\",\n",
    "    \"What's the latest news from the world of books?\",\n",
    "    \"What's the update on the latest fashion trends?\",\n",
    "    \"Can you tell me more about the latest food and drink news?\",\n",
    "    \"What's the current state of the energy industry?\",\n",
    "    \"Can you give me an update on the latest space news?\",\n",
    "    \"What's the latest news on the world economy?\",\n",
    "    \"What's the update on the latest cyber security threats?\",\n",
    "    \"Can you tell me more about the latest trends in home decor?\",\n",
    "    \"What's the current state of the job market?\",\n",
    "    \"Can you give me an update on the latest developments in artificial intelligence?\",\n",
    "    \"What's the latest news on the cryptocurrency market?\",\n",
    "    \"What's the update on the latest developments in the world of education?\",\n",
    "    \"Can you tell me more about the latest developments in the pharmaceutical industry?\",\n",
    "    \"What's the current state of the housing market?\",\n",
    "    \"Can you give me an update on the latest happenings in the world of podcasting?\",\n",
    "    \"What's the latest news from the world of theater?\",\n",
    "    \"What's the update on the latest developments in the world of augmented reality?\",\n",
    "    \"Can you tell me more about the latest developments in the world of virtual reality?\",\n",
    "    \"What's the current state of the job market for remote workers?\",\n",
    "    \"Can you give me an update on the latest climate change news?\",\n",
    "    \"What's the latest news on the world of streaming services?\",\n",
    "    \"What's the update on the latest developments in renewable energy?\",\n",
    "    \"Can you tell me more about the latest developments in 5G technology?\",\n",
    "    \"What's the current state of the cybersecurity industry?\",\n",
    "    \"Can you give me an update on the latest legal news?\",\n",
    "    \"What's happening in the world of politics?\",\n",
    "    \"What's the latest news on the world of education?\",\n",
    "    \"What's the current state of the healthcare industry?\",\n",
    "    \"What's the update on the latest sports news?\",\n",
    "    \"Can you tell me more about the latest developments in the world of music?\",\n",
    "    \"What's the current state of the fashion industry?\",\n",
    "    \"What's the latest news on the world of science?\",\n",
    "    \"Can you give me an update on the latest developments in the world of robotics?\",\n",
    "    \"What's the update on the latest social justice news?\",\n",
    "    \"What are the latest developments in the world of fitness?\",\n",
    "    \"What's the latest news on the world of travel?\",\n",
    "    \"What's the current state of the film industry?\",\n",
    "    \"Can you give me an update on the latest happenings in the world of cybersecurity?\",\n",
    "    \"What's the latest news from the world of medicine?\",\n",
    "    \"What's the update on the latest developments in the world of fashion?\",\n",
    "    \"Can you tell me more about the latest happenings in the world of sports?\",\n",
    "    \"What's the current state of the art industry?\",\n",
    "    \"Can you give me an update on the latest developments in the world of climate change?\",\n",
    "    \"What's happening in the world of technology?\",\n",
    "    \"What's the latest news on the world of finance?\",\n",
    "    \"What's the current state of the automotive industry?\",\n",
    "    \"What's the update on the latest developments in the world of space exploration?\",\n",
    "    \"Can you tell me more about the latest developments in the world of social media?\",\n",
    "    \"What's the latest news on the world of gaming?\",\n",
    "    \"What's the current state of the real estate industry?\",\n",
    "    \"Can you give me an update on the latest environmental news?\",\n",
    "    \"What's happening in the world of business?\",\n",
    "    \"What's the latest news on the world of education technology?\",\n",
    "    \"What's the update on the latest trends in the world of beauty?\",\n",
    "    \"Can you tell me more about the latest developments in the world of healthcare?\",\n",
    "    \"What's the current state of the world of art and design?\",\n",
    "    \"Can you give me an update on the latest political news?\",\n",
    "    \"What's happening in the world of renewable energy?\",\n",
    "    \"What's the latest news on the world of television?\",\n",
    "    \"What's the current state of the travel and tourism industry?\",\n",
    "    \"What's the update on the latest trends in the world of fitness?\",\n",
    "    \"Can you tell me more about the latest developments in the world of e-commerce?\",\n",
    "    \"What's the latest news on the world of advertising?\",\n",
    "    \"What's happening in the world of artificial intelligence?\",\n",
    "    \"What's the current state of the world of social justice?\",\n",
    "    \"Can you give me an update on the latest developments in the world of mobile technology?\",\n",
    "    \"What's the latest news on the world of literature?\",\n",
    "    \"What's the update on the latest happenings in the world of virtual reality?\",\n",
    "    \"Can you tell me more about the latest developments in the world of fashion and beauty?\",\n",
    "    \"What's the current state of the world of robotics and automation?\",\n",
    "    \"Can you give me an update on the latest trends in the world of food?\",\n",
    "    \"What's happening in the world of entertainment?\",\n",
    "    \"What's the latest news on the world of sports technology?\",\n",
    "    \"What's the current state of the world of music?\",\n",
    "    \"What's the update on the latest happenings in the world of gaming technology?\",\n",
    "    \"Can you tell me more about the latest developments in the world of renewable energy?\",\n",
    "    \"What's the latest news on the world of architecture and design?\",\n",
    "    \"What's happening in the world of consumer technology?\",\n",
    "    \"What's the current state of the world of mobile app development?\",\n",
    "    \"Can you give me an update on the latest happenings in the world of virtual events?\",\n",
    "    \"What's the latest news on the world of blockchain technology?\",\n",
    "    \"What's the update on the latest trends in the world of travel and tourism?\",\n",
    "    \"Can you tell me more about the latest developments in the world of social media marketing?\",\n",
    "    \"What's the current state of the world of sports and fitness?\",\n",
    "    \"Can you give me an update on the latest happenings in the world of augmented reality?\",\n",
    "    \"What's happening in the world of finance and investment?\",\n",
    "    \"What's the latest news on the world of space technology?\",\n",
    "    \"What's the current state of the world of software development?\",\n",
    "    \"What's the update on the latest happenings in the world of fashion technology?\"\n",
    "]\n",
    "medical_phrases =  [\"relieve\", \"alleviate\", \"lessen\", \"ease\", \"mitigate\", \"reduce\", \"diminish\", \"assuage\", \"pacify\", \"soothe\", \"quell\"]\n",
    "\n",
    "\n",
    "configs = [\n",
    "    [\n",
    "        google_phrases,\n",
    "        {\n",
    "            'type': 'browse', \n",
    "            'search': 'https://www.youtube.com/watch?v=NeQM1c-XCDc'\n",
    "        }\n",
    "    ], \n",
    "    [\n",
    "        actualite_phrases, \n",
    "        {\n",
    "            'type': 'tts', \n",
    "            'text': 'Bonjour'\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        medical_phrases,\n",
    "        {\n",
    "            'type': 'tts',\n",
    "            'text': 'TTT'\n",
    "        }\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rendu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTIONS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initChatbot():\n",
    "    # DO SOMETHING\n",
    "    print(\"[+] - ChatBot initialized\")\n",
    "def initSpeechRecognition():\n",
    "    # DO SOMETHING\n",
    "    print(\"[+] - Speech Recognition initialized\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Julien\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "d:\\Python\\lib\\site-packages\\spacy\\util.py:837: UserWarning: [W095] Model 'en_core_web_sm' (3.5.0) was trained with spaCy v3.5 and may not be 100% compatible with the current version (3.3.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import re\n",
    "import spacy\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "# Charger le modèle 'en' pour la langue anglaise\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def preprocess(text, strip=True, lowercase=True, cleaning_digit_url=True, remove_stopwords=True, tokenization=True):\n",
    "\n",
    "    if strip:\n",
    "        # strip\n",
    "        text = text.strip()\n",
    "\n",
    "    if lowercase:\n",
    "        # minuscule\n",
    "        text = text.lower()\n",
    "\n",
    "    if cleaning_digit_url:\n",
    "        # Expression régulière pour identifier les URLs\n",
    "        url_regex = r'http\\S+'\n",
    "        text = re.sub(url_regex, \"URL\", text)\n",
    "\n",
    "        # Expression régulière pour identifier les chiffres\n",
    "        digit_regex = r'\\d+'\n",
    "        text = re.sub(digit_regex, \"DIGIT\", text)\n",
    "\n",
    "        # Expression régulière pour identifier les users\n",
    "        user_regex = r'@\\S+'\n",
    "        text = re.sub(user_regex, \"USER\", text)\n",
    "\n",
    "    if remove_stopwords:\n",
    "        # suppression des mots vides\n",
    "        filtered_words = [word for word in text.split() if word.lower() not in stop_words]\n",
    "        text = ' '.join(filtered_words)\n",
    "\n",
    "    if tokenization:\n",
    "        # racinisation et lemmatisation\n",
    "        nlp_output = nlp(text)\n",
    "    \n",
    "    return nlp_output\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INTENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-e2m-intent\")\n",
    "# model = AutoModelWithLMHead.from_pretrained(\"mrm8488/t5-base-finetuned-e2m-intent\")\n",
    "\n",
    "# def get_intent(event, max_length=16):\n",
    "#   input_text = \"%s </s>\" % event\n",
    "#   features = tokenizer([input_text], return_tensors='pt')\n",
    "\n",
    "#   output = model.generate(input_ids=features['input_ids'], \n",
    "#                attention_mask=features['attention_mask'],\n",
    "#                max_length=max_length)\n",
    "#   return remove_html_tags(tokenizer.decode(output[0])).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_similarity_cosinus(question, corpus):\n",
    "    corpus_token = [preprocess(q).text for q in corpus]\n",
    "\n",
    "    phrase = preprocess(question).text\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Calcul du vecteur tf-idf du corpus\n",
    "    tfidf_corpus = vectorizer.fit_transform(corpus_token)\n",
    "\n",
    "    # Calcul du vecteur tf-idf de la phrase d'exemple\n",
    "    tfidf_phrase = vectorizer.transform([phrase])\n",
    "\n",
    "    # Calcul de la similarité cosinus entre la phrase d'exemple et le corpus\n",
    "    cosine_similarities = cosine_similarity(tfidf_phrase, tfidf_corpus).flatten()\n",
    "\n",
    "    # Récupération de l'indice de la phrase la plus similaire\n",
    "    most_similar_index = cosine_similarities.argmax()\n",
    "\n",
    "    return cosine_similarities[most_similar_index]\n",
    "\n",
    "def get_intention(question, corpus):\n",
    "    corpus_token = [preprocess(q).text for q in corpus ]\n",
    "\n",
    "    phrase = preprocess(question).text    \n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Calcul du vecteur tf-idf du corpus\n",
    "    tfidf_corpus = vectorizer.fit_transform(corpus_token)\n",
    "\n",
    "    # Calcul du vecteur tf-idf de la phrase d'exemple\n",
    "    tfidf_phrase = vectorizer.transform([phrase])\n",
    "\n",
    "    # Calcul de la similarité cosinus entre la phrase d'exemple et le corpus\n",
    "    cosine_similarities = cosine_similarity(tfidf_phrase, tfidf_corpus).flatten()\n",
    "\n",
    "    # Récupération de l'indice de la phrase la plus similaire\n",
    "    most_similar_index = cosine_similarities.argmax()\n",
    "\n",
    "    # Récupération de la phrase la plus similaire\n",
    "    most_similar_phrase = corpus[most_similar_index]\n",
    "\n",
    "    # print(\"Phrase d'exemple : \", phrase)\n",
    "    # print(\"Phrase la plus similaire : \", most_similar_phrase)\n",
    "    return cosine_similarities[most_similar_index]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Browse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "\n",
    "def search_on_google(search_term):\n",
    "    url = f\"https://www.google.com/search?q={search_term}\"\n",
    "    webbrowser.open_new_tab(url)\n",
    "\n",
    "def open_link(url):\n",
    "    webbrowser.open_new_tab(url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "from transformers import pipeline\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "def translate_english_to_french(text):\n",
    "    # create a translator object with the pre-trained model\n",
    "    translator = pipeline(\"translation_en_to_fr\", \n",
    "                           model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "    # translate the English text to French\n",
    "    french_text = translator(text, max_length=500)[0][\"translation_text\"]\n",
    "    return french_text\n",
    "\n",
    "def translate_french_to_english(text):\n",
    "    # create a translator object with the pre-trained model\n",
    "    translator = pipeline(\"translation_fr_to_en\",\n",
    "                          model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "    # translate the French text to English\n",
    "    english_text = translator(text)[0][\"translation_text\"]\n",
    "    return english_text\n",
    "\n",
    "def check_question(question):\n",
    "    speak('did you say : '+question + ' please response whith yes or no')\n",
    "    answer = ''\n",
    "    while (answer == ''):\n",
    "        var = get_text_audio('english')\n",
    "        print('var : '+var)\n",
    "        if 'yes' in var.lower():\n",
    "            answer = True\n",
    "        elif 'no' in var.lower():\n",
    "            answer = False\n",
    "        else:\n",
    "            speak('sorry i did not hear you can you repeat')\n",
    "    return answer\n",
    "\n",
    "def speak_general(text_fr, text_en, lang):\n",
    "    if lang == 'fr-FR':\n",
    "        speak(text_fr, lang)\n",
    "    else:\n",
    "        speak(text_en, lang)\n",
    "\n",
    "def speak_error(lang):\n",
    "    if lang == 'fr-FR':\n",
    "        speak('Pouvez-vous répéter ?', lang)\n",
    "    else:\n",
    "        speak('Can you repeat ?', lang)\n",
    "\n",
    "def speak(text, language):\n",
    "    engine = pyttsx3.init()\n",
    "    if language == 'fr-FR':\n",
    "        voice = engine.getProperty('voices')[0]\n",
    "    else:\n",
    "        voice = engine.getProperty('voices')[1]\n",
    "    engine.setProperty('voice', voice.id)  \n",
    "    engine.setProperty('rate', 150)\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def get_language():\n",
    "    language = ''\n",
    "    while (language == ''):\n",
    "        txt = get_text_audio('english')\n",
    "        if 'english' in txt.lower():\n",
    "            language = 'en-US'\n",
    "            print('you chosed english')\n",
    "        elif 'french' in txt.lower():\n",
    "            language = 'fr-FR'\n",
    "            print('you chosed french')\n",
    "        else:\n",
    "            speak('sorry i did not hear you can you repeat','en-US')\n",
    "    return language\n",
    "\n",
    "\n",
    "def get_text_audio(lang):\n",
    "    str = ''\n",
    "    while (str == ''):\n",
    "        r = sr.Recognizer()\n",
    "        with sr.Microphone() as source:\n",
    "            print(\"Je vous écoute...\")\n",
    "            audio = r.listen(source)\n",
    "        try:\n",
    "            text = r.recognize_google(audio, language=lang)\n",
    "            print(\"Recognized text:\", text)\n",
    "            str = text\n",
    "        except sr.UnknownValueError:\n",
    "            speak_error(lang)\n",
    "            print(\"Could not understand audio\")\n",
    "            str = ''\n",
    "        except sr.RequestError as e:\n",
    "            speak_error(lang)\n",
    "            print(\"Recognition request failed; {0}\".format(e))\n",
    "            str = ''\n",
    "    return str\n",
    "\n",
    "def get_question(language):\n",
    "    if language == 'fr-FR':\n",
    "        speak('Comment je peux vous aider ?', language)\n",
    "    else:\n",
    "        speak('How can i help you', language)\n",
    "    return get_text_audio(language)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "def get_news(numberNews, language):\n",
    "    url = 'https://www.lemonde.fr/'\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    news_items = soup.find_all(class_='article__title')\n",
    "    # Delete all balise html in news_items\n",
    "    news = []\n",
    "    for item in news_items:\n",
    "        new = remove_html_tags(str(item))\n",
    "        if language == 'en-US':\n",
    "            new = translate_french_to_english(new)\n",
    "        news.append(new)\n",
    "\n",
    "    return '\\n'.join(news[:numberNews])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def ask_chatGPT(prompt):\n",
    "\n",
    "    key = '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'\n",
    "    openai.api_key = key\n",
    "    openai.organization = \"org-VZgdBkF5bGIrPFVqnETxpQIq\"\n",
    "\n",
    "    completion = openai.Completion.create(\n",
    "        prompt=prompt,\n",
    "        engine=\"text-davinci-002\",\n",
    "        max_tokens=1024,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0.5\n",
    "    )\n",
    "    return completion.choices[0].text.strip()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### INITIALIZATION #########\n",
      "[o] - Initializing Speech Recognition\n",
      "[+] - Speech Recognition initialized\n",
      "[o] - Initializing ChatBot\n",
      "[+] - ChatBot initialized\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     # Initialize\n",
    "#     print(\"######### INITIALIZATION #########\")\n",
    "#     ## Speech Recognition\n",
    "#     print(\"[o] - Initializing Speech Recognition\")\n",
    "#     sr = initSpeechRecognition()\n",
    "#     ## ChatBot\n",
    "#     print(\"[o] - Initializing ChatBot\")\n",
    "#     chatbot = initChatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### START #########\n",
      "Je vous écoute...\n",
      "Recognized text: clenched\n",
      "Je vous écoute...\n",
      "Recognized text: I want to speak in French\n",
      "you chosed french\n",
      "Say something\n",
      "Je vous écoute...\n",
      "Recognized text: de quelle couleur est le cheval blanc d'Henri IV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] - Speech Recognition success\n",
      ">  You said: of what color is the white horse of Henry IV\n",
      "> TYPE GPT\n",
      "Say something\n",
      "Je vous écoute...\n",
      "Recognized text: quitter\n",
      "######## EXIT #########\n",
      "[o] - Thanks for using me\n",
      "######### END #########\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def doAction(action, question, language):\n",
    "    if action == type_browser:\n",
    "        print(\"> TYPE BROWSER\")\n",
    "        search_on_google(\"test\")\n",
    "    elif action == type_news:\n",
    "        print(\"> TYPE NEWS\")\n",
    "        speak_general('Voici les dernières nouvelles', 'Here are the latest news', language)\n",
    "        speak(get_news(2, language), language)\n",
    "    elif action == type_medical:\n",
    "        print(\"> TYPE MEDICAL\")\n",
    "    elif action == type_GPT:\n",
    "        print(\"> TYPE GPT\")\n",
    "        speak(ask_chatGPT(question), language)\n",
    "\n",
    "\n",
    "type_browser = \"BROWSER\"\n",
    "type_news = \"NEWS\"\n",
    "type_medical = \"MEDICAL\"\n",
    "type_GPT = \"GPT\"\n",
    "\n",
    "working = True\n",
    "print(\"######### START #########\")\n",
    "\n",
    "speak('Hello, Do you want to speak in english or french', 'en-US')\n",
    "language = get_language()\n",
    "\n",
    "while(working):\n",
    "    print(\"Say something\")\n",
    "    \n",
    "    original_question = get_question(language)\n",
    "    question = translate_french_to_english(original_question)\n",
    "    if any(word in question for word in ['quit', 'quitter', 'exit', 'stop']):\n",
    "        if language == 'fr-FR':\n",
    "            speak('Au revoir', language)\n",
    "        else:\n",
    "            speak('Goodbye', language)\n",
    "        working = False\n",
    "    else:\n",
    "        print(\"[+] - Speech Recognition success\")\n",
    "        print(\">  You said: \" + question)\n",
    "        \n",
    "        score_news = get_similarity_cosinus(question, actualite_phrases)\n",
    "        if score_news >= 0.65:\n",
    "            doAction(type_news, question, language)\n",
    "\n",
    "        score_google = get_similarity_cosinus(question, google_phrases)\n",
    "        if score_google >= 0.65:\n",
    "            doAction(type_browser, question, language)\n",
    "\n",
    "        score_medical = get_similarity_cosinus(question, medical_phrases)\n",
    "        if score_medical >= 0.65:\n",
    "            doAction(type_medical, question, language)\n",
    "\n",
    "        if score_news < 0.65 and score_google < 0.65 and score_medical < 0.65:\n",
    "            doAction(type_GPT, original_question, language)\n",
    "\n",
    "    \n",
    "\n",
    "print(\"######## EXIT #########\")\n",
    "print(\"[o] - Thanks for using me\")\n",
    "print(\"######### END #########\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intention : to learn\n",
      "gpt : find the definition of the word study\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
